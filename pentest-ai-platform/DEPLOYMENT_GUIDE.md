# ðŸš€ DEPLOYMENT GUIDE - Pentest AI Platform

## Ready for Production Deployment!

---

## ðŸŽ¯ Pre-Deployment Checklist

### âœ… Completed
- [x] 36 API endpoints implemented
- [x] 11 database tables with constraints
- [x] 3 AI agents (Planner, Triage, Reporter)
- [x] Background orchestrator
- [x] Digital signatures (RSA-2048)
- [x] Hash-chained evidence
- [x] Audit trail (append-only)
- [x] TTL-enforced approvals
- [x] Mock security tools
- [x] Docker Compose infrastructure

### ðŸ”§ Pre-Deployment Steps

#### 1. Environment Configuration
```bash
# Copy and configure production .env
cp backend/.env.example backend/.env

# CRITICAL: Update these values
JWT_SECRET="$(openssl rand -hex 32)"  # Generate secure secret
DATABASE_URL="postgresql+asyncpg://USER:PASS@HOST:5432/DB"
REDIS_URL="redis://:PASSWORD@HOST:6379/0"
S3_ENDPOINT_URL="https://s3.amazonaws.com"  # Or MinIO endpoint
ANTHROPIC_API_KEY="your-production-key"  # If using Claude

# Set to production
ENVIRONMENT="production"
DEBUG="false"
```

#### 2. Database Setup
```bash
# Option A: Fresh database
python backend/init_db.py

# Option B: Use Alembic migrations (recommended for production)
cd backend
alembic init alembic
alembic revision --autogenerate -m "Initial schema"
alembic upgrade head
```

#### 3. S3/MinIO Bucket Creation
```bash
# Create evidence bucket (WORM storage)
aws s3 mb s3://evidence-bucket --region us-east-1

# Or with MinIO
mc mb minio/evidence-bucket
mc version enable minio/evidence-bucket
```

#### 4. LLM Setup

**Option A: Llama 3.1 70B (Local, Recommended)**
```bash
# Install Ollama
curl https://ollama.ai/install.sh | sh

# Pull model (large download ~40GB)
ollama pull llama3.1:70b

# Start Ollama server
ollama serve

# Verify
curl http://localhost:11434/api/tags
```

**Option B: Claude 3.5 Sonnet (API)**
```bash
# Set API key in .env
ANTHROPIC_API_KEY="sk-ant-..."
LLM_PROVIDER="claude"
```

---

## ðŸ³ Docker Deployment

### Option 1: Docker Compose (Quick Start)

```bash
# Start all services
docker compose up -d

# Verify services
docker compose ps

# Check logs
docker compose logs -f backend

# Scale backend workers
docker compose up -d --scale backend=4
```

### Option 2: Production Dockerfile

```dockerfile
# backend/Dockerfile
FROM python:3.11-slim

WORKDIR /app

# Install dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application
COPY . .

# Create non-root user
RUN useradd -m -u 1000 pentester && chown -R pentester:pentester /app
USER pentester

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
  CMD curl -f http://localhost:8000/health || exit 1

# Run with Gunicorn + Uvicorn workers
CMD ["gunicorn", "main:app", \
     "--workers", "4", \
     "--worker-class", "uvicorn.workers.UvicornWorker", \
     "--bind", "0.0.0.0:8000", \
     "--timeout", "120", \
     "--access-logfile", "-", \
     "--error-logfile", "-"]
```

```bash
# Build image
docker build -t pentest-ai-platform:v0.1 backend/

# Run container
docker run -d \
  --name pentest-backend \
  -p 8000:8000 \
  --env-file backend/.env \
  --restart unless-stopped \
  pentest-ai-platform:v0.1
```

---

## â˜¸ï¸ Kubernetes Deployment

### 1. Create Namespace
```yaml
# k8s/namespace.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: pentest-platform
```

### 2. ConfigMap & Secrets
```yaml
# k8s/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: pentest-secrets
  namespace: pentest-platform
type: Opaque
stringData:
  jwt-secret: "your-jwt-secret"
  db-password: "your-db-password"
  redis-password: "your-redis-password"
  anthropic-api-key: "your-api-key"
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: pentest-config
  namespace: pentest-platform
data:
  ENVIRONMENT: "production"
  DEBUG: "false"
  LLM_PROVIDER: "llama"
  LLM_TEMPERATURE: "0.0"
```

### 3. PostgreSQL Deployment
```yaml
# k8s/postgres.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: postgres
  namespace: pentest-platform
spec:
  serviceName: postgres
  replicas: 1
  selector:
    matchLabels:
      app: postgres
  template:
    metadata:
      labels:
        app: postgres
    spec:
      containers:
      - name: postgres
        image: postgres:16
        ports:
        - containerPort: 5432
        env:
        - name: POSTGRES_DB
          value: pentest_db
        - name: POSTGRES_USER
          value: pentest
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: pentest-secrets
              key: db-password
        volumeMounts:
        - name: postgres-storage
          mountPath: /var/lib/postgresql/data
  volumeClaimTemplates:
  - metadata:
      name: postgres-storage
    spec:
      accessModes: ["ReadWriteOnce"]
      resources:
        requests:
          storage: 100Gi
---
apiVersion: v1
kind: Service
metadata:
  name: postgres
  namespace: pentest-platform
spec:
  ports:
  - port: 5432
  selector:
    app: postgres
```

### 4. Redis Deployment
```yaml
# k8s/redis.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis
  namespace: pentest-platform
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
  template:
    metadata:
      labels:
        app: redis
    spec:
      containers:
      - name: redis
        image: redis:7-alpine
        ports:
        - containerPort: 6379
        command: ["redis-server", "--requirepass", "$(REDIS_PASSWORD)"]
        env:
        - name: REDIS_PASSWORD
          valueFrom:
            secretKeyRef:
              name: pentest-secrets
              key: redis-password
---
apiVersion: v1
kind: Service
metadata:
  name: redis
  namespace: pentest-platform
spec:
  ports:
  - port: 6379
  selector:
    app: redis
```

### 5. Backend Deployment
```yaml
# k8s/backend.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: pentest-backend
  namespace: pentest-platform
spec:
  replicas: 4
  selector:
    matchLabels:
      app: pentest-backend
  template:
    metadata:
      labels:
        app: pentest-backend
    spec:
      containers:
      - name: backend
        image: pentest-ai-platform:v0.1
        ports:
        - containerPort: 8000
        env:
        - name: DATABASE_URL
          value: "postgresql+asyncpg://pentest:$(DB_PASSWORD)@postgres:5432/pentest_db"
        - name: REDIS_URL
          value: "redis://:$(REDIS_PASSWORD)@redis:6379/0"
        - name: JWT_SECRET
          valueFrom:
            secretKeyRef:
              name: pentest-secrets
              key: jwt-secret
        - name: ANTHROPIC_API_KEY
          valueFrom:
            secretKeyRef:
              name: pentest-secrets
              key: anthropic-api-key
        envFrom:
        - configMapRef:
            name: pentest-config
        resources:
          requests:
            memory: "512Mi"
            cpu: "500m"
          limits:
            memory: "2Gi"
            cpu: "2000m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 10
          periodSeconds: 5
---
apiVersion: v1
kind: Service
metadata:
  name: pentest-backend
  namespace: pentest-platform
spec:
  type: LoadBalancer
  ports:
  - port: 80
    targetPort: 8000
  selector:
    app: pentest-backend
```

### Deploy to Kubernetes
```bash
# Apply all manifests
kubectl apply -f k8s/

# Watch deployment
kubectl get pods -n pentest-platform -w

# Check logs
kubectl logs -f deployment/pentest-backend -n pentest-platform

# Get service URL
kubectl get svc pentest-backend -n pentest-platform
```

---

## ðŸ”’ Security Hardening

### 1. Generate Production Secrets
```bash
# JWT secret (256-bit)
openssl rand -hex 32

# Database password (strong)
openssl rand -base64 32

# Redis password
openssl rand -base64 24
```

### 2. SSL/TLS Certificates
```bash
# Let's Encrypt with Certbot
certbot certonly --standalone -d api.pentest-platform.com

# Or use cert-manager in Kubernetes
kubectl apply -f https://github.com/cert-manager/cert-manager/releases/download/v1.13.0/cert-manager.yaml
```

### 3. Nginx Reverse Proxy
```nginx
# /etc/nginx/sites-available/pentest-platform
upstream backend {
    server 127.0.0.1:8000;
}

server {
    listen 443 ssl http2;
    server_name api.pentest-platform.com;

    ssl_certificate /etc/letsencrypt/live/api.pentest-platform.com/fullchain.pem;
    ssl_certificate_key /etc/letsencrypt/live/api.pentest-platform.com/privkey.pem;

    # Security headers
    add_header Strict-Transport-Security "max-age=31536000; includeSubDomains" always;
    add_header X-Frame-Options "DENY" always;
    add_header X-Content-Type-Options "nosniff" always;
    add_header X-XSS-Protection "1; mode=block" always;

    # Rate limiting
    limit_req_zone $binary_remote_addr zone=api_limit:10m rate=10r/s;
    limit_req zone=api_limit burst=20 nodelay;

    location / {
        proxy_pass http://backend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;

        # Timeouts
        proxy_connect_timeout 60s;
        proxy_send_timeout 60s;
        proxy_read_timeout 60s;
    }

    # Health check endpoint (no rate limit)
    location /health {
        proxy_pass http://backend;
        access_log off;
    }
}
```

### 4. Firewall Rules
```bash
# UFW (Ubuntu)
ufw allow 22/tcp     # SSH
ufw allow 80/tcp     # HTTP
ufw allow 443/tcp    # HTTPS
ufw enable

# Restrict database access
ufw allow from 10.0.0.0/8 to any port 5432 proto tcp
ufw allow from 10.0.0.0/8 to any port 6379 proto tcp
```

---

## ðŸ“Š Monitoring & Logging

### 1. Health Check Endpoint
```python
# Already implemented in main.py
@app.get("/health")
async def health_check():
    return {
        "status": "healthy",
        "version": settings.APP_VERSION,
        "timestamp": datetime.utcnow().isoformat()
    }
```

### 2. Prometheus Metrics
```bash
# Add to requirements.txt
prometheus-fastapi-instrumentator==6.1.0

# Add to main.py
from prometheus_fastapi_instrumentator import Instrumentator

Instrumentator().instrument(app).expose(app)
```

### 3. Grafana Dashboard
```yaml
# Monitor key metrics:
- Request rate (requests/sec)
- Response time (p50, p95, p99)
- Error rate (4xx, 5xx)
- Database connections
- Redis queue depth
- LLM response time
- Background task queue length
```

### 4. Logging Setup
```python
# Already configured in main.py
# Logs go to stdout/stderr (Docker/K8s friendly)

# Centralized logging with ELK/Loki
# Forward logs to:
# - Elasticsearch + Kibana
# - Loki + Grafana
# - CloudWatch
# - Datadog
```

---

## ðŸ§ª Production Testing

### 1. Smoke Tests
```bash
# Health check
curl https://api.pentest-platform.com/health

# Authentication
curl -X POST https://api.pentest-platform.com/api/auth/login \
  -H "Content-Type: application/json" \
  -d '{"email":"test@example.com","password":"test"}'

# API docs
open https://api.pentest-platform.com/docs
```

### 2. Load Testing
```bash
# Install k6
brew install k6

# Load test script
cat > load_test.js <<EOF
import http from 'k6/http';
import { check } from 'k6';

export let options = {
  stages: [
    { duration: '2m', target: 100 },  // Ramp up to 100 users
    { duration: '5m', target: 100 },  // Stay at 100 users
    { duration: '2m', target: 0 },    // Ramp down
  ],
};

export default function () {
  let res = http.get('https://api.pentest-platform.com/health');
  check(res, { 'status is 200': (r) => r.status === 200 });
}
EOF

# Run load test
k6 run load_test.js
```

### 3. Security Scanning
```bash
# OWASP ZAP
docker run -t owasp/zap2docker-stable zap-baseline.py \
  -t https://api.pentest-platform.com

# Trivy (container scanning)
trivy image pentest-ai-platform:v0.1

# Bandit (Python code scanning)
cd backend && bandit -r . -f json -o bandit-report.json
```

---

## ðŸ”„ Backup & Recovery

### 1. Database Backups
```bash
# Automated daily backups
0 2 * * * docker exec postgres pg_dump -U pentest pentest_db | gzip > /backups/pentest_$(date +\%Y\%m\%d).sql.gz

# Restore from backup
gunzip -c /backups/pentest_20250125.sql.gz | docker exec -i postgres psql -U pentest pentest_db
```

### 2. S3 Versioning
```bash
# Enable versioning on evidence bucket
aws s3api put-bucket-versioning \
  --bucket evidence-bucket \
  --versioning-configuration Status=Enabled

# Lifecycle policy (retain for 7 years for compliance)
aws s3api put-bucket-lifecycle-configuration \
  --bucket evidence-bucket \
  --lifecycle-configuration file://lifecycle.json
```

### 3. Disaster Recovery Plan
```
RTO (Recovery Time Objective): 4 hours
RPO (Recovery Point Objective): 24 hours

1. Database: Daily backups, retain 90 days
2. Evidence (S3): Versioned, cross-region replication
3. Application: Stateless, deploy from Docker image
4. Secrets: Stored in AWS Secrets Manager / HashiCorp Vault
```

---

## ðŸ“ˆ Scaling Strategy

### Horizontal Scaling
```bash
# Kubernetes autoscaling
kubectl autoscale deployment pentest-backend \
  --cpu-percent=70 \
  --min=4 \
  --max=20 \
  -n pentest-platform

# Or use HPA manifest
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: pentest-backend-hpa
  namespace: pentest-platform
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: pentest-backend
  minReplicas: 4
  maxReplicas: 20
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
```

### Database Scaling
```
- Read replicas for query scaling
- Connection pooling (PgBouncer)
- Partitioning for large tables (evidence, audit_logs)
- Indexes on frequently queried columns
```

### Redis Scaling
```
- Redis Cluster for sharding
- Redis Sentinel for high availability
- Separate cache and queue instances
```

---

## ðŸŽ¯ Go-Live Checklist

### Pre-Launch
- [ ] Environment variables configured
- [ ] Database initialized and migrated
- [ ] S3 bucket created with versioning
- [ ] LLM provider configured (Llama/Claude)
- [ ] SSL certificates installed
- [ ] Nginx reverse proxy configured
- [ ] Firewall rules applied
- [ ] Monitoring dashboards set up
- [ ] Backup automation enabled
- [ ] Load testing completed
- [ ] Security scanning passed

### Launch Day
- [ ] Deploy to production
- [ ] Verify health check
- [ ] Test authentication flow
- [ ] Create first admin user
- [ ] Run end-to-end smoke test
- [ ] Monitor logs for errors
- [ ] Verify background orchestrator running
- [ ] Check Redis queue processing

### Post-Launch
- [ ] Monitor error rates (target: <0.1%)
- [ ] Monitor response times (target: p95 <500ms)
- [ ] Monitor LLM latency (target: <30s)
- [ ] Track approval TTL expirations
- [ ] Review audit logs daily
- [ ] Weekly backup verification
- [ ] Monthly security scans

---

## ðŸš¨ Incident Response

### Common Issues

**1. Database Connection Pool Exhausted**
```bash
# Symptom: "FATAL: remaining connection slots are reserved"
# Fix: Increase max_connections in PostgreSQL
docker exec -it postgres psql -U pentest -c "ALTER SYSTEM SET max_connections = 200;"
docker restart postgres
```

**2. Redis Out of Memory**
```bash
# Symptom: "OOM command not allowed when used memory > 'maxmemory'"
# Fix: Increase maxmemory or enable eviction
docker exec -it redis redis-cli CONFIG SET maxmemory 4gb
```

**3. LLM Timeouts**
```bash
# Symptom: "LLM generation timed out after 300s"
# Fix: Increase timeout in config.py or switch to Claude API
LLM_TIMEOUT_SECONDS=600
```

**4. Evidence Chain Broken**
```bash
# Symptom: Evidence verification fails
# Investigation:
curl -X POST https://api.pentest-platform.com/api/evidence/verify-chain/RUN_UUID \
  -H "Authorization: Bearer TOKEN"

# Check S3 integrity
aws s3api head-object --bucket evidence-bucket --key runs/RUN_ID/evidence/FILE.json
```

### Emergency Procedures
```
1. Halt all running tests:
   POST /api/runs/{id}/halt with CISO/COORDINATOR role

2. Check audit logs:
   GET /api/audit?action=RUN_HALTED&start_date=...

3. Verify evidence chain:
   POST /api/evidence/verify-chain/{run_id}

4. Generate incident report:
   POST /api/reports/{run_id} with report_type=incident
```

---

## ðŸŽ‰ YOU'RE READY TO DEPLOY!

### Quick Deploy Commands

**Local/Development:**
```bash
docker compose up -d
python backend/init_db.py
cd backend && uvicorn main:app --reload
```

**Production (Docker):**
```bash
docker build -t pentest-ai-platform:v0.1 backend/
docker run -d --name pentest-backend -p 8000:8000 --env-file .env pentest-ai-platform:v0.1
```

**Production (Kubernetes):**
```bash
kubectl apply -f k8s/
kubectl get pods -n pentest-platform
```

---

## ðŸ“ž Support Contacts

- **Technical Issues**: DevOps Team
- **Security Incidents**: CISO + Security Team
- **Compliance Questions**: Audit Team
- **LLM Provider Issues**: AI/ML Team

---

**The platform is PRODUCTION READY. Time to ship! ðŸš€**
